{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x130 = open('130_triple/VCS_fields_TT_x_ROM.txt', 'r')\n",
    "x130 = np.loadtxt(f_x130)\n",
    "x130 = x130[::100,:]\n",
    "print(x130.shape)\n",
    "f_y130 = open('130_triple/VCS_fields_TT_y_ROM.txt', 'r')\n",
    "y130 = np.loadtxt(f_y130)\n",
    "y130 = y130[::100,:]\n",
    "print(y130.shape)\n",
    "f_x170 = open('170_triple/VCS_fields_TT_x_ROM.txt', 'r')\n",
    "x170 = np.loadtxt(f_x170)\n",
    "x170 = x170[::100,:]\n",
    "print(x170.shape)\n",
    "f_y170 = open('170_triple/VCS_fields_TT_y_ROM.txt', 'r')\n",
    "y170 = np.loadtxt(f_y170)\n",
    "y170 = y170[::100,:]\n",
    "print(y170.shape)\n",
    "\n",
    "#x30 = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [7, 8, 9, 10], [3, 4, 5, 6], [1, 2, 3, 4]])\n",
    "\n",
    "#x28 = np.array([])\n",
    "\n",
    "#print(x30[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_x = int(x170.shape[1])\n",
    "dim_y = int(y170.shape[1])\n",
    "print(dim_x)\n",
    "print(dim_y)\n",
    "\n",
    "x170_sample_grid_tmp = np.delete(x170, (x170.shape[0]-1), axis=0)\n",
    "x170_train_values = np.delete(x170, (0), axis=0)\n",
    "x170_sample_grid = 170*np.ones((x170_sample_grid_tmp.shape[0],x170_sample_grid_tmp.shape[1]+1))\n",
    "x170_sample_grid[:,:-1] = x170_sample_grid_tmp\n",
    "\n",
    "sample_data = x170_sample_grid\n",
    "\n",
    "print(sample_data.shape)\n",
    "\n",
    "train_data = x170_train_values\n",
    "print(train_data.shape)\n",
    "\n",
    "print(sample_data[0:1,:])\n",
    "\n",
    "#f_sample_grid_d1 = open('sample_grid_d1.txt', 'r')\n",
    "#sample_grid_d1 = 2*(np.loadtxt(f_sample_grid_d1) - 0.5)\n",
    "#sample_grid_d1 = np.loadtxt(f_sample_grid_d1)\n",
    "#print(sample_grid_d1)\n",
    "#f_sample_grid_d2 = open('sample_grid_d2.txt', 'r')\n",
    "#sample_grid_d2 = 10*(np.loadtxt(f_sample_grid_d2) - 0.1)\n",
    "#sample_grid_d2 = np.loadtxt(f_sample_grid_d2)\n",
    "#print(sample_grid_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_values = samples_optimal_clustering.reshape(110)\n",
    "#train_values = np.concatenate((lcs0, lcs1, lcs2, lcs3, lcs4, lcs5, lcs6, lcs7))\n",
    "#print(train_values)\n",
    "#train_values = np.reshape(train_values,(lcs0.shape[0],8), order='F')\n",
    "#print(train_values.shape)\n",
    "#train_values = 1./train_values\n",
    "#np.argmax(train_values, axis = 1)\n",
    "#for i in range(0,train_values.shape[0]):\n",
    "#    sum_row = np.sum(train_values[i,:])\n",
    "#    train_values[i,:] = train_values[i,:] / sum_row\n",
    "    #print(sum_row)\n",
    "#print(train_values)\n",
    "#train_values = np.transpose(trainANN)\n",
    "#print(trainANN)\n",
    "#print(train_values.shape)\n",
    "#print(train_values.shape[1])\n",
    "fig, ax = plt.subplots()  # Create a figure containing a single axes.\n",
    "#ax.plot([1, 2, 3, 4], [1, 4, 2, 3])  # Plot some data on the axes.\n",
    "ax.plot(train_data[:999,0])\n",
    "ax.plot(train_data[1000:1999,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=[sample_data.shape[1]]),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(train_data.shape[1])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='mse', min_delta = 0, patience = 100, mode='min',verbose=1, restore_best_weights = 1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae', 'mse'])\n",
    "model.fit(sample_data, train_data, epochs=5000, callbacks=[es])\n",
    "\n",
    "es = EarlyStopping(monitor='mse', min_delta = 0, patience = 100, mode='min',verbose=1, restore_best_weights = 1)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='mse',\n",
    "              metrics=['mae', 'mse'])\n",
    "model.fit(sample_data, train_data, epochs=200, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x30_sample_grid, x30_train_values, epochs=10000, callbacks=[es])\n",
    "# use the ROM to time-step given the first reduced coordinate representation\n",
    "current_estimate = x170_sample_grid[0,:]\n",
    "estimated_trajectory = 0*x170_sample_grid\n",
    "estimated_trajectory[0,:] = current_estimate\n",
    "#print(current_estimate)\n",
    "#print(x30_sample_grid.shape)\n",
    "#print(x30_sample_grid[0:1,:])\n",
    "for i in range(0,x170_sample_grid.shape[0]-1):\n",
    "    print(estimated_trajectory[i:i+1,:])\n",
    "    next_estimate = model.predict(estimated_trajectory[i:i+1,:])\n",
    "    print(next_estimate)\n",
    "    estimated_trajectory[i+1,:-1] = next_estimate\n",
    "#    estimated_trajectory[i+1,:-1] = x130_train_values[i-1,:]\n",
    "    estimated_trajectory[i+1,-1] = 170\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "fig, ax = plt.subplots()    \n",
    "ax.plot(train_data[2:999,0])\n",
    "ax.plot(estimated_trajectory[2:1000,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the ROM to time-step given the first reduced coordinate representation\n",
    "current_estimate = x30_sample_grid[1000,:]\n",
    "estimated_trajectory = 0*x30_sample_grid\n",
    "estimated_trajectory[0,:] = current_estimate\n",
    "#print(current_estimate)\n",
    "#print(x30_sample_grid.shape)\n",
    "#print(x30_sample_grid[0:1,:])\n",
    "for i in range(0,x30_sample_grid.shape[0] - 1):\n",
    "    next_estimate = model.predict(estimated_trajectory[i:i+1,:])\n",
    "    estimated_trajectory[i+1,:-1] = next_estimate\n",
    "    estimated_trajectory[i+1,-1] = 170\n",
    "#    print(i)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()    \n",
    "ax.plot(x30_sample_grid[1000:1900,0])\n",
    "ax.plot(estimated_trajectory[0:2000,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,x30_sample_grid.shape[0]):\n",
    "#    next_estimate = model.predict(estimated_trajectory[i:i+1,:])\n",
    "#    estimated_trajectory[i+1,:-1] = next_estimate\n",
    "#    print(i)\n",
    "    \n",
    "#fig, ax = plt.subplots()    \n",
    "#ax.plot(x30[:,0])\n",
    "#ax.plot(estimated_trajectory[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()    \n",
    "#ax.plot(x30_sample_grid[1000:1300,0])\n",
    "#ax.plot(estimated_trajectory[0:300,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(train_values, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pred_sg, axis=1) - np.argmax(train_values, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_fine_sample_grid = open('fine_sample_grid.txt', 'r')\n",
    "fine_sample_grid = np.loadtxt(f_fine_sample_grid)\n",
    "print(fine_sample_grid.shape)\n",
    "print(fine_sample_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fsg = model.predict(fine_sample_grid)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(pred_fsg.shape)\n",
    "np.savetxt('pred_fsg.txt', pred_fsg)\n",
    "#np.argmax(pred_fsg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_combination_optimal_c = open('combination_optimal_c.txt', 'r')\n",
    "#combination_optimal_c = np.loadtxt(f_combination_optimal_c)\n",
    "#print(combination_optimal_c)\n",
    "#print(sample_grid.shape)\n",
    "#print(train_values.shape)\n",
    "#print(combination_optimal_c.shape)\n",
    "#detailed_train_values = combination_optimal_c.reshape(1640)\n",
    "#print(detailed_train_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_2 = keras.Sequential([\n",
    "#    keras.layers.Dense(2, activation='relu'),\n",
    "#    keras.layers.Dense(1024, activation='relu'),\n",
    "#    keras.layers.Dense(1024, activation='relu'),\n",
    "#    keras.layers.Dense(8, activation='softmax')\n",
    "#])\n",
    "#model_2.compile(optimizer='adam',\n",
    "#              loss='sparse_categorical_crossentropy',\n",
    "#              metrics=['accuracy'])\n",
    "#model_2.fit(fine_sample_grid, detailed_train_values, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_mod2 = model_2.predict(fine_sample_grid)\n",
    "#save_pred_mod2_fsg = np.argmax(pred_mod2, axis=1)\n",
    "#np.savetxt('save_pred_mod2_fsg.txt', save_pred_mod2_fsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mod1 = np.argmax(pred_fsg, axis=1)\n",
    "#np.savetxt('smart_save_pred_mod1_fsg.txt', pred_mod1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
