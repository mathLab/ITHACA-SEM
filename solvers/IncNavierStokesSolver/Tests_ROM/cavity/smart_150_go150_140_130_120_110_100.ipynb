{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x150 = open('150_triple/VCS_fields_TT_x_ROM.txt', 'r')\n",
    "x150 = np.loadtxt(f_x150)\n",
    "x150 = x150[::100,:]\n",
    "print(x150.shape)\n",
    "f_y150 = open('150_triple/VCS_fields_TT_y_ROM.txt', 'r')\n",
    "y150 = np.loadtxt(f_y150)\n",
    "y150 = y150[::100,:]\n",
    "print(y150.shape)\n",
    "\n",
    "f_x140 = open('140_triple/VCS_fields_TT_x_ROM.txt', 'r')\n",
    "x140 = np.loadtxt(f_x140)\n",
    "x140 = x140[::100,:]\n",
    "print(x140.shape)\n",
    "f_y140 = open('140_triple/VCS_fields_TT_y_ROM.txt', 'r')\n",
    "y140 = np.loadtxt(f_y140)\n",
    "y140 = y140[::100,:]\n",
    "print(y140.shape)\n",
    "\n",
    "f_x130 = open('130_triple/VCS_fields_TT_x_ROM.txt', 'r')\n",
    "x130 = np.loadtxt(f_x130)\n",
    "x130 = x130[::100,:]\n",
    "print(x130.shape)\n",
    "f_y130 = open('130_triple/VCS_fields_TT_y_ROM.txt', 'r')\n",
    "y130 = np.loadtxt(f_y130)\n",
    "y130 = y130[::100,:]\n",
    "print(y130.shape)\n",
    "f_x120 = open('120_triple/VCS_fields_TT_x_ROM.txt', 'r')\n",
    "x120 = np.loadtxt(f_x120)\n",
    "x120 = x120[::100,:]\n",
    "print(x120.shape)\n",
    "f_y120 = open('120_triple/VCS_fields_TT_y_ROM.txt', 'r')\n",
    "y120 = np.loadtxt(f_y120)\n",
    "y120 = y120[::100,:]\n",
    "print(y120.shape)\n",
    "f_x110 = open('110_triple/VCS_fields_TT_x_ROM.txt', 'r')\n",
    "x110 = np.loadtxt(f_x110)\n",
    "x110 = x110[::100,:]\n",
    "print(x110.shape)\n",
    "f_y110 = open('110_triple/VCS_fields_TT_y_ROM.txt', 'r')\n",
    "y110 = np.loadtxt(f_y110)\n",
    "y110 = y110[::100,:]\n",
    "print(y110.shape)\n",
    "f_x100 = open('100_triple/VCS_fields_TT_x_ROM.txt', 'r')\n",
    "x100 = np.loadtxt(f_x100)\n",
    "x100 = x100[::100,:]\n",
    "print(x100.shape)\n",
    "f_y100 = open('100_triple/VCS_fields_TT_y_ROM.txt', 'r')\n",
    "y100 = np.loadtxt(f_y100)\n",
    "y100 = y100[::100,:]\n",
    "print(y100.shape)\n",
    "\n",
    "#x30 = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [7, 8, 9, 10], [3, 4, 5, 6], [1, 2, 3, 4]])\n",
    "\n",
    "#x28 = np.array([])\n",
    "\n",
    "#print(x30[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_x = int(x130.shape[1])\n",
    "dim_y = int(y130.shape[1])\n",
    "print(dim_x)\n",
    "print(dim_y)\n",
    "\n",
    "#sample_data_130 = np.transpose(np.array([np.linspace(0,1,1000),130*np.linspace(1,1,1000)]))\n",
    "#sample_data_120 = np.transpose(np.array([np.linspace(0,1,1000),120*np.linspace(1,1,1000)]))\n",
    "#sample_data_110 = np.transpose(np.array([np.linspace(0,1,1000),110*np.linspace(1,1,1000)]))\n",
    "\n",
    "x150_sample_grid_tmp = np.delete(x150, (x150.shape[0]-1), axis=0)\n",
    "x150_train_values = np.delete(x150, (0), axis=0)\n",
    "x150_sample_grid = 150*np.ones((x150_sample_grid_tmp.shape[0],x150_sample_grid_tmp.shape[1]+1))\n",
    "x150_sample_grid[:,:-1] = x150_sample_grid_tmp\n",
    "\n",
    "x140_sample_grid_tmp = np.delete(x140, (x140.shape[0]-1), axis=0)\n",
    "x140_train_values = np.delete(x140, (0), axis=0)\n",
    "x140_sample_grid = 140*np.ones((x140_sample_grid_tmp.shape[0],x140_sample_grid_tmp.shape[1]+1))\n",
    "x140_sample_grid[:,:-1] = x140_sample_grid_tmp\n",
    "\n",
    "x130_sample_grid_tmp = np.delete(x130, (x130.shape[0]-1), axis=0)\n",
    "x130_train_values = np.delete(x130, (0), axis=0)\n",
    "x130_sample_grid = 130*np.ones((x130_sample_grid_tmp.shape[0],x130_sample_grid_tmp.shape[1]+1))\n",
    "x130_sample_grid[:,:-1] = x130_sample_grid_tmp\n",
    "\n",
    "print(x130_sample_grid.shape)\n",
    "print(x130_train_values.shape)\n",
    "\n",
    "x120_sample_grid_tmp = np.delete(x120, (x120.shape[0]-1), axis=0)\n",
    "x120_train_values = np.delete(x120, (0), axis=0)\n",
    "x120_sample_grid = 120*np.ones((x120_sample_grid_tmp.shape[0],x120_sample_grid_tmp.shape[1]+1))\n",
    "x120_sample_grid[:,:-1] = x120_sample_grid_tmp\n",
    "\n",
    "x110_sample_grid_tmp = np.delete(x110, (x110.shape[0]-1), axis=0)\n",
    "x110_train_values = np.delete(x110, (0), axis=0)\n",
    "x110_sample_grid = 110*np.ones((x110_sample_grid_tmp.shape[0],x110_sample_grid_tmp.shape[1]+1))\n",
    "x110_sample_grid[:,:-1] = x110_sample_grid_tmp\n",
    "\n",
    "x100_sample_grid_tmp = np.delete(x100, (x100.shape[0]-1), axis=0)\n",
    "x100_train_values = np.delete(x100, (0), axis=0)\n",
    "x100_sample_grid = 100*np.ones((x100_sample_grid_tmp.shape[0],x100_sample_grid_tmp.shape[1]+1))\n",
    "x100_sample_grid[:,:-1] = x100_sample_grid_tmp\n",
    "\n",
    "\n",
    "\n",
    "sample_data = np.r_[x150_sample_grid, x140_sample_grid, x130_sample_grid, x120_sample_grid, x110_sample_grid, x100_sample_grid]\n",
    "train_data = np.r_[x150_train_values, x140_train_values, x130_train_values, x120_train_values, x110_train_values, x100_train_values]\n",
    "\n",
    "\n",
    "print(sample_data.shape)\n",
    "print(train_data.shape)\n",
    "\n",
    "\n",
    "#f_sample_grid_d1 = open('sample_grid_d1.txt', 'r')\n",
    "#sample_grid_d1 = 2*(np.loadtxt(f_sample_grid_d1) - 0.5)\n",
    "#sample_grid_d1 = np.loadtxt(f_sample_grid_d1)\n",
    "#print(sample_grid_d1)\n",
    "#f_sample_grid_d2 = open('sample_grid_d2.txt', 'r')\n",
    "#sample_grid_d2 = 10*(np.loadtxt(f_sample_grid_d2) - 0.1)\n",
    "#sample_grid_d2 = np.loadtxt(f_sample_grid_d2)\n",
    "#print(sample_grid_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_values = samples_optimal_clustering.reshape(110)\n",
    "#train_values = np.concatenate((lcs0, lcs1, lcs2, lcs3, lcs4, lcs5, lcs6, lcs7))\n",
    "#print(train_values)\n",
    "#train_values = np.reshape(train_values,(lcs0.shape[0],8), order='F')\n",
    "#print(train_values.shape)\n",
    "#train_values = 1./train_values\n",
    "#np.argmax(train_values, axis = 1)\n",
    "#for i in range(0,train_values.shape[0]):\n",
    "#    sum_row = np.sum(train_values[i,:])\n",
    "#    train_values[i,:] = train_values[i,:] / sum_row\n",
    "    #print(sum_row)\n",
    "#print(train_values)\n",
    "#train_values = np.transpose(trainANN)\n",
    "#print(trainANN)\n",
    "#print(train_values.shape)\n",
    "#print(train_values.shape[1])\n",
    "fig, ax = plt.subplots()  # Create a figure containing a single axes.\n",
    "#ax.plot([1, 2, 3, 4], [1, 4, 2, 3])  # Plot some data on the axes.\n",
    "ax.plot(train_data[:999,0])\n",
    "ax.plot(train_data[1000:1998,0])\n",
    "ax.plot(train_data[1999:2997,0])\n",
    "ax.plot(train_data[2998:3996,0])\n",
    "ax.plot(train_data[3997:4995,0])\n",
    "ax.plot(train_data[4996:5995,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='relu', input_shape=[sample_data.shape[1]]),\n",
    "    keras.layers.Dense(256, activation='softplus'),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(train_data.shape[1])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='mse', min_delta = 0, patience = 100, mode='min',verbose=1, restore_best_weights = 1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae', 'mse'])\n",
    "model.fit(sample_data, train_data, epochs=10000, callbacks=[es])\n",
    "\n",
    "es = EarlyStopping(monitor='mse', min_delta = 0, patience = 100, mode='min',verbose=1, restore_best_weights = 1)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='mse',\n",
    "              metrics=['mae', 'mse'])\n",
    "model.fit(sample_data, train_data, epochs=2000, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x30_sample_grid, x30_train_values, epochs=10000, callbacks=[es])\n",
    "# use the ROM to time-step given the first reduced coordinate representation\n",
    "current_estimate = x130_sample_grid[0,:]\n",
    "estimated_trajectory = np.r_[0*x130_sample_grid, 0*x130_sample_grid, 0*x130_sample_grid, 0*x130_sample_grid]\n",
    "estimated_trajectory[0,:] = current_estimate\n",
    "#print(current_estimate)\n",
    "#print(x30_sample_grid.shape)\n",
    "#print(x30_sample_grid[0:1,:])\n",
    "for i in range(0,4*x130_sample_grid.shape[0]-1):\n",
    "    print(estimated_trajectory[i:i+1,:])\n",
    "    next_estimate = model.predict(estimated_trajectory[i:i+1,:])\n",
    "    print(next_estimate)\n",
    "    estimated_trajectory[i+1,:-1] = next_estimate\n",
    "#    estimated_trajectory[i+1,:-1] = x130_train_values[i-1,:]\n",
    "    estimated_trajectory[i+1,-1] = 130\n",
    "#    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "fig, ax = plt.subplots()    \n",
    "ax.plot(x130_sample_grid[0:1000,0])\n",
    "ax.plot(estimated_trajectory[0:4000,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x30_sample_grid, x30_train_values, epochs=10000, callbacks=[es])\n",
    "# use the ROM to time-step given the first reduced coordinate representation\n",
    "current_estimate = x120_sample_grid[0,:]\n",
    "estimated_trajectory = np.r_[0*x120_sample_grid, 0*x120_sample_grid, 0*x120_sample_grid, 0*x120_sample_grid]\n",
    "estimated_trajectory[0,:] = current_estimate\n",
    "#print(current_estimate)\n",
    "#print(x30_sample_grid.shape)\n",
    "#print(x30_sample_grid[0:1,:])\n",
    "for i in range(0,4*x120_sample_grid.shape[0]-1):\n",
    "    print(estimated_trajectory[i:i+1,:])\n",
    "    next_estimate = model.predict(estimated_trajectory[i:i+1,:])\n",
    "    print(next_estimate)\n",
    "    estimated_trajectory[i+1,:-1] = next_estimate\n",
    "#    estimated_trajectory[i+1,:-1] = x130_train_values[i-1,:]\n",
    "    estimated_trajectory[i+1,-1] = 120\n",
    "#    print(i)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()    \n",
    "ax.plot(x120_sample_grid[0:1000,0])\n",
    "ax.plot(estimated_trajectory[0:4000,0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x30_sample_grid, x30_train_values, epochs=10000, callbacks=[es])\n",
    "# use the ROM to time-step given the first reduced coordinate representation\n",
    "current_estimate = x110_sample_grid[0,:]\n",
    "estimated_trajectory = np.r_[0*x110_sample_grid, 0*x110_sample_grid, 0*x110_sample_grid, 0*x110_sample_grid]\n",
    "estimated_trajectory[0,:] = current_estimate\n",
    "#print(current_estimate)\n",
    "#print(x30_sample_grid.shape)\n",
    "#print(x30_sample_grid[0:1,:])\n",
    "for i in range(0,4*x110_sample_grid.shape[0]-1):\n",
    "    print(estimated_trajectory[i:i+1,:])\n",
    "    next_estimate = model.predict(estimated_trajectory[i:i+1,:])\n",
    "    print(next_estimate)\n",
    "    estimated_trajectory[i+1,:-1] = next_estimate\n",
    "#    estimated_trajectory[i+1,:-1] = x130_train_values[i-1,:]\n",
    "    estimated_trajectory[i+1,-1] = 110\n",
    "#    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()    \n",
    "ax.plot(x110_sample_grid[0:1000,0])\n",
    "ax.plot(estimated_trajectory[0:4000,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.argmax(train_values, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.argmax(pred_sg, axis=1) - np.argmax(train_values, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_fine_sample_grid = open('fine_sample_grid.txt', 'r')\n",
    "#fine_sample_grid = np.loadtxt(f_fine_sample_grid)\n",
    "#print(fine_sample_grid.shape)\n",
    "#print(fine_sample_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_fsg = model.predict(fine_sample_grid)\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "#print(pred_fsg.shape)\n",
    "#np.savetxt('pred_fsg.txt', pred_fsg)\n",
    "#np.argmax(pred_fsg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_combination_optimal_c = open('combination_optimal_c.txt', 'r')\n",
    "#combination_optimal_c = np.loadtxt(f_combination_optimal_c)\n",
    "#print(combination_optimal_c)\n",
    "#print(sample_grid.shape)\n",
    "#print(train_values.shape)\n",
    "#print(combination_optimal_c.shape)\n",
    "#detailed_train_values = combination_optimal_c.reshape(1640)\n",
    "#print(detailed_train_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_2 = keras.Sequential([\n",
    "#    keras.layers.Dense(2, activation='relu'),\n",
    "#    keras.layers.Dense(1024, activation='relu'),\n",
    "#    keras.layers.Dense(1024, activation='relu'),\n",
    "#    keras.layers.Dense(8, activation='softmax')\n",
    "#])\n",
    "#model_2.compile(optimizer='adam',\n",
    "#              loss='sparse_categorical_crossentropy',\n",
    "#              metrics=['accuracy'])\n",
    "#model_2.fit(fine_sample_grid, detailed_train_values, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_mod2 = model_2.predict(fine_sample_grid)\n",
    "#save_pred_mod2_fsg = np.argmax(pred_mod2, axis=1)\n",
    "#np.savetxt('save_pred_mod2_fsg.txt', save_pred_mod2_fsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_mod1 = np.argmax(pred_fsg, axis=1)\n",
    "#np.savetxt('smart_save_pred_mod1_fsg.txt', pred_mod1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
